{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지도학습 : 선형회귀 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수작업으로 그래프를 그리며 데이터셋에 적합시키는 모델은 시간이 무한정 소요되므로 적합하지 않다.  \n",
    "더 복잡한 머신러닝/딥러닝 문제들로 들어가면 비선형 관계를 찾기 시작할 것이며  \n",
    "변수가 많은 복잡한 식을 사용하게 될 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서 배우게 될 머신러닝 훈련 기법은 그 문제들에도 동일하게 적용할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일을 읽고 레코드를 출력한다. \n",
    "features = pd.read_csv('../data/house_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  처음 8개의 점을 훈련셋으로 분리(0~7)  \n",
    "x_train = features[['Area', 'Locality']].values[:7]\n",
    "y_train = features[['Price']].values[:7]\n",
    "\n",
    "# 마지막 2개의 점을 테스트 셋으로 분할\n",
    "x_test = features[['Area', 'Locality']].values[7:]\n",
    "y_test = features[['Price']].values[7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터셋은 모델의 가중치 학습에 사용되고   \n",
    "테스트 데이터셋은 모델이 처음 본 데이터에도 잘 예측하고 테스트하는 지 확인하는 데 사용될 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최대한 잘 적합되었다는 것은 어떻게 판단할 수 있을까??  \n",
    "이를 위해 비용함수가 필요하다.  \n",
    "비용함수는 기본적으로 모델의 예측값이 실제 값과 얼마나 차이나는가를 측정하는 수단이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비용 함수는 예측값과 실제 값의 차이를 계량해야 한다. 수치값 출력을 예측하는 경우,  \n",
    "각 훈련 데이터의 예측값과 실제 값의 차이를 합산해 구할 수 있다.  \n",
    "만일 클래스를 예측하는 경우라면, 분류 오차를 계량화하는 함수를 사용할 수 있을 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비용 함수를 오차 함수라고도 하는데, 이는 오차함수가 예측 상의 오차를 계량화하기 때문이다.  \n",
    "비용함수를 최적화의 목적함수로 사용할 수 있다. 가중치 값을 최적화해 비용 함수의 값을 최소화한다.  \n",
    "이것은 전통적인 최적화 문제가 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사하강 최적화 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 X들을 모델에 통과시켜 Y를 예측한다.  \n",
    "예측값들을 실제 값들과 비교해 오차를 구한다.  \n",
    "비용함수의 각 가중치 및 편향에 대한 경사도를 구한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사도는 기본적으로 각 가중치/편향에 대한 비용함수의 편도함수(partial derivative)이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경사도는 특정한 가중치 및 편향이 비용에 미치는 영향의 크기와 방향을 알려준다.  \n",
    "이 값을 이용해 비용을 감소시키는 방향으로 가중치와 편향을 보정한다 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAE(평균 절댓값 오차) : mean(abs(y-y'))\n",
    "- MSE(평균 제곱 오차) : mean((y-y')^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가중치를 경사도 방향으로 얼마만큼 보정할 것인지는 학습률이라는 상수 파라미터로 조절한다.  \n",
    "학습률을 너무 크게 잡으면 최소값을 지나쳐서 곡선의 다른 쪽에 떨어지게 될 수 있다.  \n",
    "학습률이 너무 작으면 가중치가 충분히 보정되지 않으므로 학습 과정이 너무 느려진다.  \n",
    "일반적으로 0.05로 시작하는 것이 무난하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights are:  [[ 0.19319908 14.27643887]]\n",
      "Model intercept is:  [-49.75481457]\n",
      "predicting for  [225   4]\n",
      "Expected Value:  [60]\n",
      "Predicted Value:  [[39.98129196]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn의 내장함수를 써서 선형 회귀 모델을 적용한다. \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Model weights are: \", model.coef_)\n",
    "print(\"Model intercept is: \", model.intercept_)\n",
    "\n",
    "# 테스트 데이터셋의 한 샘플에 대한 예측 \n",
    "print('predicting for ', x_test[0])\n",
    "print('Expected Value: ', y_test[0])\n",
    "print(\"Predicted Value: \", model.predict([[95, 5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회귀 모델의 평가에는 MSE/MAE 측도가 사용되며, 그 결과값이 높게 나온다면 다른 회귀 모델을 생각해봐야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만일 선형 모델을 사용하는 데 오차 값이 계속 나온다면 일반적으로 더 복잡한 비선형 모델을 검토하기 시작해야 한다.  \n",
    "비선형회귀 방법 중에 가장 유명한 것이 신경망이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망으로 데이터 내의 비선형성을 포착할 수 있으며, 오차가 작은 모델을 찾을 수 있다.  \n",
    "신경망처럼 복잡한 모델에 대해서 실제 값과 예측값 간의 오차를 네트워크로 전파하고  \n",
    "가중치와 편향에 대한 비용함수의 경사(gradient)를 빠르게 계산할 수 있게 해주는 역전파라고 하는 매우 정교한 알고리즘을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지도학습 - 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류에서 결과 또는 종속변수는 값이 아니라 클래스 멤버십이다.  \n",
    "결과는 0에서부터 클래스 개수까지의 정수 값을 가질 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 회귀의 값을 선형 분류의 값으로 설정할 수 있다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이중 분류의 경우, 먼저 선형 회귀에서처럼 변수들 간의 선형 관계를 학습한다.  \n",
    "그런 다음 sigmoid 활성화 함수를 서서 0과 1 사이의 값으로 변환한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 선형 가중 합계를 sigmoid 함수에 넣은 0과 1 사이의 값이  \n",
    "어떤 임계값 이상이면 1로 분류하고, 아니면 0으로 분류한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망을 이용하여 다중 클래스 분류 문제로 확장할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주택의 면적/크기, 가격, 구입 여부를 나타내는 열 한 개가 추가된 데이터가 있다고 하자.  \n",
    "이 열은 주택을 사면 1, 안 사면 0으로 표시될 것이다.  \n",
    "이제 고객이 주택을 살 것인지 안 살 것인지 예측하는 이유에 대한 모델을 컴퓨터가 예측하게 하고 싶다.  \n",
    "앞의 예제에서처럼, 데이터를 훈련셋과 테스트 셋으로 분리하자.  \n",
    "마지막 두 점을 테스트용 데이터로 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/house_sale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Price</th>\n",
       "      <th>Buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Area  Locality  Price  Buy\n",
       "0   100         4     30    0\n",
       "1   250         5     80    1\n",
       "2   220         5     80    1\n",
       "3   105         6     40    1\n",
       "4   150         8    100    0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음 8개의 점을 훈련 데이터로 분리(0~7)\n",
    "x_train = features[['Area', 'Locality', 'Price']].values[:8]\n",
    "x_temp = features[['Area', 'Locality', 'Price']][:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   4  30]\n",
      " [250   5  80]\n",
      " [220   5  80]\n",
      " [105   6  40]\n",
      " [150   8 100]\n",
      " [180   9 120]\n",
      " [225   4  60]\n",
      " [ 95   5  40]] <class 'numpy.ndarray'>\n",
      "   Area  Locality  Price\n",
      "0   100         4     30\n",
      "1   250         5     80\n",
      "2   220         5     80\n",
      "3   105         6     40\n",
      "4   150         8    100\n",
      "5   180         9    120\n",
      "6   225         4     60\n",
      "7    95         5     40 <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(x_train, type(x_train)) # numpy.ndarray\n",
    "print(x_temp, type(x_temp)) # pandas.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = features['Buy'].values[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 2 점을 테스트 데이터로 분리\n",
    "x_test = features[['Area', 'Locality', 'Price']].values[8:]\n",
    "y_test = features['Buy'].values[8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 훈련 데이터에 로지스틱 회귀 모델을 적용하자. 그리고 훈련된 모델로  \n",
    "두 테스트 점들에 대해 예측해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 테스트 데이터에서 예측\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# 예상값 출력 \n",
    "print(y_pred)\n",
    "\n",
    "# 마지막 2 점들은 테스트 데이터로 \n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대단히 제한적인 데이터로부터 꽤 좋은 결과를 얻었다.   \n",
    "그러나, 로지스틱 회귀는 데이터의 비선형 관계는 담아내지 못한다는 한계가 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 결정 경계는 변수들 간의 비선형 관계를 가지고 있으므로 고급 분류 방법이 사용되어야 한다.  \n",
    "K-평균, 결정 트리, 랜덤 포레스트 및 더 복잡한 신경망 등이 그것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 더 큰 데이터셋의 분석  \n",
    "사용할 데이터셋은 UCI에 공개되어 있는 와인 품질 데이터셋이다.  \n",
    "- 독립변수(feature): 와인의 회분(ash), 알코올 농도(alcohol) 등 같은 여러 가지 화학적 속성들이다.  \n",
    "- 종속변수: 전문가가 판정한 와인의 등급 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# csv 파일을 읽고 레코드들을 표시하기 \n",
    "features = pd.read_csv('../data/winequality-red.csv')\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 features 데이터프레임을 x와 y 프레임으로 분리한다.  \n",
    "그런 다음 다시 훈련 프레임과 테스트 프레임으로 나눈다.  \n",
    "훈련과 테스트 프레임의 비율이 80과 20이 되도록 무작위로 섞어 분리한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x's features:  Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
      "      dtype='object')\n",
      "y's columns:  Index(['quality'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x = features # all features\n",
    "x.drop(['quality'], axis = 1) # y를 features로부터 분리한 것 \n",
    "y = features[['quality']] # y만 features로 만든 것 # 리스트 두개 씌워야함 \n",
    "\n",
    "print(\"x's features: \", x.columns)\n",
    "print(\"y's columns: \", y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_features: X (1279, 12) (1279, 1)\n",
      "Test features: y (320, 12) (320, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2\n",
    ")\n",
    "print(\"Training_features: X\", x_train.shape, y_train.shape)\n",
    "print(\"Test features: y\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도에 대한 측도: 정밀도 및 재현율  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 알고리즘과 비교하여 어떤 것이 더 정확한 지 비교하기 위해,  \n",
    "하이퍼파라미터를 조정함으로써 예측 성능을 크게 개선할 수 있는데, 이 변화한 성능을 측정하기 위해  \n",
    "정확도에 대한 측도가 필요하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nn](../screenshots/001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정밀도(precision) =  \n",
    "$$Precision = True Positive / (True Positive + False Positive)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재현율(Recall) =  \n",
    "$$Recall = TruePositive / (TruePositive + FalseNegative)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선, 로지스틱회귀를 이용해 와인 품질 데이터를 분류해 보자.  \n",
    "와인의 종류별로 잘 구분되어 있으므로, 모델 평가를 위한 주 측도로서 정밀도를 사용한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,) <class 'numpy.ndarray'>\n",
      "(320, 1) <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/com/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/com/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  \n",
    "import numpy as np\n",
    "\n",
    "# 모델 구축 \n",
    "model = LogisticRegression()\n",
    "# 훈련 데이터에 적합시키기 \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# x_test에 대해서 y_test 예측하기\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(y_pred.shape, type(y_pred)) # numpy \n",
    "print(y_test.shape, type(y_test)) # pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320,)\n",
      "own_정밀도:  0.846875\n",
      "Precision for Logistic Regression:  0.846875\n"
     ]
    }
   ],
   "source": [
    "# y_test와 비교해서 정밀도 측정하기\n",
    "# 공식대로 내가 직접 구현한 정밀도 \n",
    "comparison = y_pred == np.array(y_test['quality'])\n",
    "print(comparison.shape)\n",
    "\n",
    "precision_own = np.count_nonzero(comparison == True) / len(y_pred)\n",
    "print(\"own_정밀도: \", precision_own)\n",
    "\n",
    "# 교재의 방식 \n",
    "from sklearn.metrics import precision_score\n",
    "# 예측에 대한 정밀도 계산 \n",
    "print(\"Precision for Logistic Regression: \", precision_score(y_test, y_pred, average='micro')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 알고리즘을 더 추가해 모델을 만들어 보자.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-최근접 이웃 모델(KNN - K-Nearest Neighbors)  \n",
    "k개의 가장 가까운 이웃들을 기반으로 예측하도록 학습한다.  \n",
    "새로운 점이 주어지면, 그 점과 가장 가까운 k개의 점들의 소속을 기반으로 새롤운 점의 소속 클래스 예측  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for KNN:  0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/com/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN 모델 훈련 \n",
    "model = KNeighborsClassifier(n_neighbors = 20)\n",
    "model.fit(x_train, y_train)\n",
    "# x_test에 대한 예측 \n",
    "y_pred = model.predict(x_test)\n",
    "# y_test와의 비교 \n",
    "print(\"Precision for KNN: \", precision_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn 알고리즘은 훈련 데이터 전체를 보며, 각 신규 점에 대해서 가장 근접한 이웃 점들을 기반으로 점수를 낸다.  \n",
    "KNN은 일반적으로 시간이 꽤 걸리며, 최고의 정확도가 나오지 않을 수도 있다.  \n",
    "다른 알고리즘을 살펴보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정 트리 전체를 구축하고 시각화할 수 있다.  \n",
    "약간 복잡하지만 결정 트리를 시각화하고 싶다면 이 리스트처럼 하면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KNeighborsClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m export_graphviz\n\u001b[1;32m      3\u001b[0m \u001b[39m# dot 파일 형식으로 저장 \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m export_graphviz(model, \n\u001b[1;32m      5\u001b[0m     out_file \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m../screenshots/tree.dot\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      6\u001b[0m     feature_names\u001b[39m=\u001b[39;49mx_train\u001b[39m.\u001b[39;49mcolumns, \n\u001b[1;32m      7\u001b[0m     class_names\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m(\u001b[39m6\u001b[39;49m), \n\u001b[1;32m      8\u001b[0m     rounded \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, proportion \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, \n\u001b[1;32m      9\u001b[0m     precision\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, filled\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/tree/_export.py:905\u001b[0m, in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision, fontname)\u001b[0m\n\u001b[1;32m    886\u001b[0m     out_file \u001b[39m=\u001b[39m StringIO()\n\u001b[1;32m    888\u001b[0m exporter \u001b[39m=\u001b[39m _DOTTreeExporter(\n\u001b[1;32m    889\u001b[0m     out_file\u001b[39m=\u001b[39mout_file,\n\u001b[1;32m    890\u001b[0m     max_depth\u001b[39m=\u001b[39mmax_depth,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    903\u001b[0m     fontname\u001b[39m=\u001b[39mfontname,\n\u001b[1;32m    904\u001b[0m )\n\u001b[0;32m--> 905\u001b[0m exporter\u001b[39m.\u001b[39;49mexport(decision_tree)\n\u001b[1;32m    907\u001b[0m \u001b[39mif\u001b[39;00m return_string:\n\u001b[1;32m    908\u001b[0m     \u001b[39mreturn\u001b[39;00m exporter\u001b[39m.\u001b[39mout_file\u001b[39m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/tree/_export.py:465\u001b[0m, in \u001b[0;36m_DOTTreeExporter.export\u001b[0;34m(self, decision_tree)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurse(decision_tree, \u001b[39m0\u001b[39m, criterion\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimpurity\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurse(decision_tree\u001b[39m.\u001b[39;49mtree_, \u001b[39m0\u001b[39m, criterion\u001b[39m=\u001b[39mdecision_tree\u001b[39m.\u001b[39mcriterion)\n\u001b[1;32m    467\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtail()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# dot 파일 형식으로 저장 \n",
    "export_graphviz(model, \n",
    "    out_file = '../screenshots/tree.dot', \n",
    "    feature_names=x_train.columns, \n",
    "    class_names=range(6), \n",
    "    rounded = True, proportion = False, \n",
    "    precision=1, filled=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앙상블 기법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "많은 약분류기들의 예측을 결합해 강분류기를 구축하는 방법  \n",
    "결정 트리에 앙상블 기법을 적용하면 랜덤 포레스트라고 하는 새로운 알록리즘이 탄생한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "랜덤 포레스트 :  \n",
    "- 특성들의 부분집합과 데이터의 부분집합을 랜덤하게 선택한다.  \n",
    "- 이 축소된 데이터를 가지고 결정 트리를 만든다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성과 행들의 부분집합을로 여러 개의 결정 트리를 구축하고,  \n",
    "그 결과들을 종합해 예측한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "회귀 모델을 구축하기 위해 랜덤 포레스트를 사용할 수도 있으며, 이 경우 각 트리의 평균값을 최종 답으로 출력한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/com/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 100개의 랜덤 트리를 갖는 모델을 구축한다.  \n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# 훈련 데이터 사용 \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 \n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (320,)\n",
      "<class 'pandas.core.frame.DataFrame'> (320, 1)\n",
      "own_정밀도:  0.846875\n",
      "Precision for Random-Forest:  0.978125\n"
     ]
    }
   ],
   "source": [
    "# 정밀도 출력 - 내가 직접 만든 정밀도\n",
    "print(type(y_pred), y_pred.shape)\n",
    "print(type(y_test), y_test.shape)\n",
    "\n",
    "precision_own = np.count_nonzero(comparison == True) / len(y_pred)\n",
    "print(\"own_정밀도: \", precision_own)\n",
    "\n",
    "# 교재 - 정밀도 출력 \n",
    "print(\"Precision for Random-Forest: \", precision_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블 기법을 사용해 훨씬 좋은 정밀도를 얻었다.  \n",
    "앙상블 기법은 트리에만 국한되지 않으며, 다른 알고리즘들로도 결과물을 결합해  \n",
    "분류기 대열을 만들 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편향 대 분산 : 미적합 대 과적합 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다트 보드에 다섯 개의 다트를 던진다고 생각해 보자.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다섯 개의 다트가 좌측 상단에 잘 맞는 것은, 중심에는 잘 안 맞지만 아주 고르게 맞은 경우이다.  \n",
    "이 경우는 큰 편향이 있는 경우이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다섯 개의 다트가 보드 전체에 걸쳐 넓게 맞는 경우는 큰 분산이 존재하는 경우이다.  \n",
    "이것이 큰 분산의 경우이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편향과 분산을 조정해 타겟에 맞게 조준해야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제는 테스트 데이터에 대한 정밀도만 구하지 않고, 훈련 데이터와 테스트 데이터를 통한 정밀도 모두를 구할 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pricision for train data:  0.8592650508209538\n",
      "Precision for test data:  0.846875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/com/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/com/anaconda3/envs/env-keras/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "# 로지스틱 회귀 모델의 구축 \n",
    "model = LogisticRegression()\n",
    "\n",
    "# 모델을 데이터에 맞춘다. \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# 훈련 데이터에 대한 예측 및 정밀도 \n",
    "y_pred = model.predict(x_train)\n",
    "print(\"Pricision for train data: \", precision_score(y_train, y_pred, average='micro'))\n",
    "\n",
    "# 테스트 데이터에 대한 예측 및 정밀도\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"Precision for test data: \", precision_score(y_pred, y_test, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터에 대한 정밀도가 테스트 데이터에 대한 정밀도와 거의 동일하다.  \n",
    "훈련 데이터에 더 잘 맞아야 한다. 이것은 미적합에 해당한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미적합이란 훈련 데이터에서나 테스트 데이터에서 모두 잘 맞지 않은 경우이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것은 편향이라는 머신러닝 모델의 속성 때문에 발생한다.  \n",
    "편향은 모델이 세우는 가정(assumption)에 해당하며, 편향이 크면 모델은 데이터로부터 잘 학습하지 못한다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에게 편향은 어느 정도 필요하다.  \n",
    "그렇지 않으면 모델은 입력 데이터의 변동성에 대하여 매우 취약해지며 불량한 데이터가 들어오면 모델은 실수하게 될 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Train data:  1.0\n",
      "Precision for test data:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "# 모델을 데이터에 적합시키기\n",
    "model.fit(x_train, y_train)\n",
    "# 훈련 데이터에 대한 적합도 \n",
    "y_pred = model.predict(x_train)\n",
    "print(\"Precision for Train data: \", precision_score(y_train, y_pred, average='micro'))\n",
    "\n",
    "# 테스트 데이터에 대한 적합도\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"Precision for test data: \", precision_score(y_pred, y_test, average='micro'))\n",
    "# 원래 0.6XXX가 나와야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터에 대한 정밀도는 100%인 반면, 테스트 데이터에 대한 정밀도는 떨어진다.  \n",
    "이 모델은 훈련 데이터 패턴은 극도로 잘 학습하지 못헀다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 모델은 큰 분산을 가졌다고 말하며, 훈련 데이터에 대하여 과적합하였다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 테스트 데이터로서 제공하는 보지 못한 데이터에 대해서 모델이 잘 일반화하기를 원한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 모델의 분산은 입력 데이터의 변동에 따라 예측을 변경할 수 있는 능력을 결정한다.  \n",
    "분산이 크다는 것은 입력 데이터에 적합하기 위해 모델이 예측을 계속 변경하기만 하고  \n",
    "정말 패턴을 학습하지 못한다는 것을 의미한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산과 편향은 반비례한다. 편향을 크게 하면 분산이 작아지고 역도 성립한다.  \n",
    "일반적으로 데이터 과학자는 편향과 분산 간의 절충을 받아들여야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정 트리와 랜덤 포레스트는 일반적으로 분산이 매우 크고 과적합하는 경향이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 현실 세계 데이터의 속성을 고려할 때, 편향이 너무 커지지 않으면서  \n",
    "데이터의 모든 변동성을 포착하기 위해서는 대부분의 경우 비선형 모델이 필요하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특성 수가 증가하고, 데이터셋이 더 복잡해지면, 특히 이미지, 텍스트, 오디오 등 비선형 데이터의 경우,  \n",
    "데이터에 더 적합하고 모든 비선형성을 잡아낼 수 있는 더 복잡한 모델을 고려해야 한다.  \n",
    "이것이 머신러닝에 속하는 딥러닝이라고 하는 또다른 커다란 분야의 시작이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
