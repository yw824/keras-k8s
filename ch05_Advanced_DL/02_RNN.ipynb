{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이론 정리 페이지 : https://www.notion.so/leew-work/CH05-3-2cee0bd14001433cb5979d99e8ef6d21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras에서 제공하는 IMDB를 사용할 예정  \n",
    "- 표준 어휘를 사용해 영화 리뷰를 정수 배열로 변환한 데이터셋  \n",
    "- 감정 분류하는 방법 학습 -> 새로운 텍스트에 대해 동일한 예 실행시켜 모델 검증 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장들 : 감정이 긍정 <-> 부정을 나타내는 레이블과 함께 정수 배열 형태로 제공됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 라이브러리, 그리고 imdb 데이터셋 로드\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Embedding \n",
    "from keras.layers import LSTM \n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading data...   \n",
      "x_train shape: (25000, 50)\n",
      "x_test shape: (25000, 50)\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에서 로드할 단어의 최대 수 지정 \n",
    "max_features = 20000\n",
    "\n",
    "# 문장의 최대 단어 수와 batch 크기 지정 \n",
    "maxlen = 50\n",
    "batch_size = 32\n",
    "\n",
    "# 데이터 로드 \n",
    "print('  Loading data...   ')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 문장의 패딩 \n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터를 탐색하려고 한다.  \n",
    "정수 배열을 보고 전체 문장을 얻기 위해 어휘를 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 배열 샘플 =  [2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16 5345   19  178   32]\n",
      "y_train 배열 샘플 =  1\n",
      "Vocabulary =  {'with': 16, 'i': 10, 'as': 14, 'it': 9, 'is': 6, 'in': 8, 'but': 18, 'of': 4, 'this': 11, 'a': 3, 'for': 15, 'br': 7, 'the': 1, 'was': 13, 'and': 2, 'to': 5, 'film': 19, 'movie': 17, 'that': 12}\n"
     ]
    }
   ],
   "source": [
    "# 데이터 샘플 표시해 보기 \n",
    "print(\"x_train 배열 샘플 = \", x_train[0])\n",
    "print(\"y_train 배열 샘플 = \", y_train[0])\n",
    "\n",
    "# 단어를 숫자로 변환하는 데 사용된 어휘 가져오기 \n",
    "imdb_vocab = imdb.get_word_index()\n",
    "\n",
    "# 단어를 숫자로 변환하는 데 사용된 어휘 가져오기 \n",
    "# 이것은 단지 어휘 목록의 생김새를 이해하기 위한 목적이다. \n",
    "small_vocab = {key: value for key, value in imdb_vocab.items() if value < 20}\n",
    "print('Vocabulary = ', small_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 배열에서 문장을 얻는 함수 \n",
    "# 어휘에서 단어를 역조화(reverse look-up)한다. \n",
    "def get_original_text(int_arr):\n",
    "    word_to_id = {k: (v+3) for k, v in imdb_vocab.items()}\n",
    "    word_to_id['<PAD>'] = 0\n",
    "    \n",
    "    word_to_id['<START>'] = 1\n",
    "    word_to_id['<UNK>'] = 2\n",
    "    \n",
    "    id_to_word = {value: key for key, value in word_to_id.items()}\n",
    "    return ' '.join(id_to_word[id] for id in int_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측은 0과 1 사이의 값  \n",
    "- 0에 가까운 값 : 감정이 긍정\n",
    "- 1에 가까운 값 : 감정이 부정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "문장 및 감정 샘플\n",
      "훈련 문장 =  grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "감정 =  Positive\n",
      "---------------------------\n",
      "훈련 문장 =  boobs and <UNK> taking away bodies and the gym still doesn't close for <UNK> all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
      "감정 =  Negative\n",
      "---------------------------\n",
      "훈련 문장 =  must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <UNK> this is to watch save yourself an hour a bit of your life\n",
      "감정 =  Negative\n",
      "---------------------------\n",
      "훈련 문장 =  man to see a film that is true to scotland this one is probably unique if you maybe <UNK> on it deeply enough you might even re evaluate the power of storytelling and the age old question of whether there are some truths that cannot be told but only experienced\n",
      "감정 =  Positive\n",
      "---------------------------\n",
      "훈련 문장 =  the <UNK> and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\n",
      "감정 =  Negative\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "# 감정 배열 정의 \n",
    "sentiment_labels = ['Positive', 'Negative'] # 0이 긍정이므로 0번째 index, 1이 부정이므로 1번째 index\n",
    "\n",
    "print(\"================================================\")\n",
    "print(\"문장 및 감정 샘플\")\n",
    "\n",
    "# 훈련 데이터의 일부를 출력 \n",
    "for i in range(5):\n",
    "    print(\"훈련 문장 = \", get_original_text(x_train[i]))\n",
    "    print(\"감정 = \", sentiment_labels[y_train[i]])\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델 구축하고 훈련  \n",
    "앞의 Conv2D와 Dense Layer 대신 Embedding과 LSTM 계층 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 30ms/step - accuracy: 0.7298 - loss: 0.5208 - val_accuracy: 0.8205 - val_loss: 0.3990\n",
      "Epoch 2/2\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.8825 - loss: 0.2839 - val_accuracy: 0.8102 - val_loss: 0.4209\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8059 - loss: 0.4271\n",
      "Test score: 0.420929491519928\n",
      "Accuracy:  0.8101599812507629\n"
     ]
    }
   ],
   "source": [
    "# 모델 구축 \n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid')) # 긍정-부정 이진 분류\n",
    "\n",
    "# 다른 최적화기들과 최적화기의 다른 설정을 사용해 본다. \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련 \n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size, \n",
    "    epochs=2, \n",
    "    validation_data=(x_test, y_test)\n",
    ")\n",
    "\n",
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print(\"Test score:\", score)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 H5 형식인 imdb_nlp.h5 파일에 저장한다.  \n",
    "저장된 모델 파일을 당장은 사용하지 않을 것이지만,  \n",
    "8장 - 모델 배포 - 에서 사용할 예정  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측은 0과 1 사이의 값  \n",
    "- 0에 가까운 값 : 감정이 긍정\n",
    "- 1에 가까운 값 : 감정이 부정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# 문장에 대해 예측하기 \n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "# 먼저 모델을 저장한다. \n",
    "model.save('imdb_nlp.h5')\n",
    "\n",
    "# imdb 데이터셋에서 단어 색인을 가져오기 \n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# 문서 정의 \n",
    "my_sentence1 = 'really bad experience. amazingly bad.'\n",
    "my_sentence2 = 'pretty awesome to see. very good work.'\n",
    "\n",
    "# 모델을 사용해 감정을 예측하는 함수 정의 \n",
    "def predict_sentiment(my_test):\n",
    "    # 문장 토큰화\n",
    "    word_sequence = text_to_word_sequence(my_test)\n",
    "    \n",
    "    # 빈 정수 시퀀스 생성 \n",
    "    int_sequence = []\n",
    "    \n",
    "    # 문장의 각 단어에 대해 \n",
    "    for w in word_sequence:\n",
    "        # word_index(vocabulary)에서 정수를 읽어와 리스트에 추가 \n",
    "        int_sequence.append(word_index[w])\n",
    "        \n",
    "    # 숫자 시퀀스를 모델 입력 크기에 맞게 패딩 \n",
    "    sent_test = sequence.pad_sequences([int_sequence], maxlen=maxlen)\n",
    "    \n",
    "    # 모델을 사용한 예측 \n",
    "    y_pred = model.predict(sent_test)\n",
    "    \n",
    "    return y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "SENTENCE:  really bad experience. amazingly bad.  :  0.7849308 : SENTIMENT :  Positive\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "SENTENCE:  pretty awesome to see. very good work.  :  0.15248412 : SENTIMENT :  Negative\n"
     ]
    }
   ],
   "source": [
    "# 문장들에 대해 결과 출력 \n",
    "print(\n",
    "    'SENTENCE: ', my_sentence1, \" : \", \n",
    "    predict_sentiment(my_sentence1), \n",
    "    \": SENTIMENT : \", \n",
    "    sentiment_labels[int(round(predict_sentiment(my_sentence1)))]\n",
    ")\n",
    "\n",
    "print(\n",
    "    'SENTENCE: ', my_sentence2, \" : \", \n",
    "    predict_sentiment(my_sentence2), \n",
    "    \": SENTIMENT : \", \n",
    "    sentiment_labels[int(round(predict_sentiment(my_sentence2)))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반대로 됐다,,,, 뭐지 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
